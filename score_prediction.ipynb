{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark and initiate\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create SparkSession using pyspark configuration\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf()\n",
    "spark = SparkSession.builder.appName(\"project\").config(conf = conf).getOrCreate()\n",
    "spark\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in merged dataset\n",
    "df=spark.read.parquet(\"hdfs://ip-172-31-74-188.ec2.internal:8020/user/hadoop/df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use transformers and encoders to perform feature engineering\n",
    "\n",
    "#import packages\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#string indices have already been created for calculating correlations\n",
    "#create vectorizer that makes one column based on all predictor variables\n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=[\"authorindex\", \n",
    "               \"subredditindex\", \n",
    "               \"parentindex\", \n",
    "               \"controversiality\",\n",
    "              \"timeofday\"], \n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "split_data = df.randomSplit([0.7, 0.3])\n",
    "train_data = split_data[0]\n",
    "test_data = split_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build linear regression model and train using pipeline\n",
    "\n",
    "#import packages\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#define logistic regression model\n",
    "mod = LinearRegression(labelCol=\"score\", featuresCol=\"features\")\n",
    "\n",
    "#set up pipeline\n",
    "pipeline_mod = Pipeline(stages=[vectorAssembler_features,\n",
    "                                mod])\n",
    "\n",
    "#train model using pipeline\n",
    "modelfit = pipeline_mod.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions for testing data using model\n",
    "prediction=modelfit.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|score|        prediction|\n",
      "+-----+------------------+\n",
      "|    1|0.9458396412692883|\n",
      "|    1| 0.956243936734744|\n",
      "|    1|0.9664326674986342|\n",
      "|    1|0.9784053967623598|\n",
      "|    1|0.8903783219941612|\n",
      "|    1| 1.001273574083964|\n",
      "|    1| 1.017993737946242|\n",
      "|    1|1.0210840676303992|\n",
      "|    1|1.0302469285501399|\n",
      "|    1|1.0544763892063593|\n",
      "|    1|1.0606832907839443|\n",
      "|    1| 1.085401399520182|\n",
      "|    3|1.0844369223066959|\n",
      "|    1| 1.111419497755214|\n",
      "|    1|1.1087807907669842|\n",
      "|    1|1.1523305298585649|\n",
      "|    1|1.1442318968277834|\n",
      "|    1| 1.151942101194694|\n",
      "|   -2|1.0687774363646336|\n",
      "|    1|1.1729950655630355|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate performance of model on testing data\n",
    "selected = prediction.select(\"score\", \"prediction\")\n",
    "selected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to double and rdd\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "selected=selected.withColumn('score', col('score').cast(DoubleType()))\n",
    "selectedrdd=selected.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 26.829615697666057\n",
      "RMSE = 5.179731237976162\n",
      "R-squared = -423.3891187328598\n",
      "Explained variance = 26.892454511574584\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "#create metrics object\n",
    "metrics = RegressionMetrics(selectedrdd)\n",
    "\n",
    "#print squared errors\n",
    "print(\"MSE = %s\" % metrics.meanSquaredError)\n",
    "print(\"RMSE = %s\" % metrics.rootMeanSquaredError)\n",
    "\n",
    "# printR-squared\n",
    "print(\"R-squared = %s\" % metrics.r2)\n",
    "\n",
    "# print explained variance\n",
    "print(\"Explained variance = %s\" % metrics.explainedVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
